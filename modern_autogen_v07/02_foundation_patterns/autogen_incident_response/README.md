# MagenticOne: Autonomous Incident Response Orchestrator

## ðŸ“Œ Impact Case Study
**The Problem:** Distributed system outages (e.g., `503 Service Unavailable`) are expensive and stressful. A typical Level 1 SRE takes **5-15 minutes** to manually verify environments, grep logs, and identify root causes, often risking production safety during the chaos.

**The Solution:** An Autonomous Incident Response Agent (MagenticOne) that dynamically plans investigations and executes safe diagnostic code in Docker containers.

**The Impact:** 
> "I automated the L1 Incident Response lifecycle, **reducing diagnosis time by 90% (from ~5 minutes to <30 seconds)** and eliminating manual error risks through isolated Docker sandboxing."

**Enterprise Readiness:** Included security considerations (Docker sandbox), audit logs, and error handling that showed production thinking.

---

## ðŸ—ï¸ Architecture

The system uses a **Dynamic Orchestration** pattern where a central "Brain" (Orchestrator) manages specialized workers.

![MagenticOne Architecture](Untitled%20Diagram.drawio.png)

### ðŸ”„ Step-by-Step Execution Flow
While the diagram shows the structure, the actual execution happens in this order:
1.  **Alert (Trigger):** User starts the system with a task (e.g., "Analyze the outage").
2.  **Plan:** The **Orchestrator** analyzes the request and decides it first needs to verify the environment.
3.  **Action 1 (Verify):** Delegates to **Coder Agent** to run `platform.platform()` inside Docker.
    *   *Result:* Confirms it's running in Linux (Docker), not Windows (Host).
4.  **Action 2 (Investigate):** Delegates to **FileSurfer** to read `production_logs.txt`.
    *   *Result:* Agent retrieves the specific "fatal: remaining connection slots" error.
5.  **Synthesis (Step 8):** Orchestrator identifies the root cause (Database Starvation) from the log data.
6.  **Action 3 (Fix/Document):** Delegates to **Coder Agent** to write `post_mortem.txt` with the findings.
7.  **Final Report:** Orchestrator compiles everything into `final_report.md` and terminates.

### Key Components
1.  **MagenticOne Orchestrator (The Brain):** Powered by Gemini 2.0 Flash, it breaks down the vague "fix this" command into specific steps (e.g., "Check logs", "Verify DB connection").
2.  **Coder Agent (The Hands):** Writes and executes Python code to test hypotheses. Critically, it runs inside a **Docker Container** to ensure `rm -rf /` doesn't destroy the host.
3.  **FileSurfer (The Eyes):** A specialized agent designed solely for navigating and reading local log files.

---

---

## ðŸ›¡ï¸ Enterprise Readiness

This is not just a script; it is a **Production-Grade Pattern** designed for secure enterprise environments.

| Feature | Implementation | Why It Matters |
| :--- | :--- | :--- |
| **Security Sandbox** | `DockerCommandLineCodeExecutor` | Prevents "rogue agent" commands (`rm -rf`) from touching the host OS. **Zero Trust architecture.** |
| **Audit Logging** | `logging` + `final_report.md` | Every decision and tool output is logged to `magentic_one.log`. Essential for **compliance & debugging**. |
| **Resource Safety** | `async with` Context Managers |Guarantees Docker containers are destroyed even if the script crashes, preventing **resource leaks**. |
| **Error Handling** | Global `try/except` with traceback | Catches runtime failures gracefully and logs specific error traces instead of silent crashes. |

## ðŸ› ï¸ Setup Instructions

### 1. Prerequisites
*   **Docker Desktop**: Must be installed and running (Required for the `Coder` agent).
*   **Python 3.10+**
*   **Gemini API Key**: Get one from Google AI Studio.

### 2. Installation
```bash
# Install AutoGen and Extensions
pip install -r ../requirements.txt
# OR manually:
pip install autogen-agentchat "autogen-ext[openai,docker,magentic-one]" python-dotenv
```

### 3. Configuration
Create a `.env` file in the root of your project:
```env
GEMINI_API_KEY=your_api_key_here
```

---

## ðŸš€ Usage

Run the orchestrator:

```bash
python magentic_one_orchestrator.py
```

### What Happens Next?
1.  The script generates a mock `production_logs.txt` file containing a complex PostgreSQL connection error.
2.  It spins up a temporary **Docker Container**.
3.  The **Orchestrator** reads the logs, realizes it's a database starvation issue, and verifies the environment.
4.  It produces a `final_report.md` with the root cause analysis.
5.  Docker container is automatically destroyed.

---


### Limitations
*   **Docker Latency:** Starting the container takes 2-4 seconds per run. Not suitable for sub-second real-time chat.
*   **Loop Risk:** Without `max_turns` or a capable model (like Gemini 2.0 / GPT-4o), the Orchestrator can get stuck in a planning loop.
*   **Filesystem Access:** The Docker container maps the current directory. Be careful with what sensitive data resides in the folder.

---